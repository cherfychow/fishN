---
title: "ch 1 fishN: data exploration"
output: 
  html_document:
    toc: true
    toc_float:
      collapsed: true
    theme: cosmo
    highlighter: tango
    df_print: paged
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F)
require(dplyr)
require(stringr)
require(ggplot2)
require(patchwork)
require(lubridate)
# custom palettes to be extra
source('https://gist.githubusercontent.com/cherfychow/e9ae890fd16f4c86730748c067feee2b/raw/899dcfc1745421cb4e6ba26826b0bfe55fd8ec14/cherulean.R')

data_ruv <- read.csv('../data/ruv_himb_pilot.csv', header = T)
```

Initial pilot checks and data exploration for comparing fish assemblage observation results from underwater visual census, remote underwater video MaxN counts, and abundance estimates from **Random encounter staying time (REST) modelling**.

### Targets to keep in mind

-   Check species overlap between cameras, but this might not be an issue
-   Check occurrence replicates per species per site, bc *power*.
-   Check overlaps with UVC species
-   Check species accumulation curves
-   Occurrence staying time distributions (check asymmetry for distribution function selections)

## Some overall tallies {.tabset}

Checking and exploring some overall counts and tallies for the RUV data, aggregated by site and species. Species especially important because rarer species with fewer occurrences will have lower replicates/sample size for the REST model.

### Site

Total number of fish occurrences, total distinct species, total camera tallies.

```{r RUV tallies, site}
data_ruv %>% group_by(site_ID) %>% 
  summarise(totobs = sum(Count),  # observations
            totsp = n_distinct(Taxon), # species
            cameras = n_distinct(Camera)
            )
```

### Species

```{r RUV tallies, species}
data_ruv %>% group_by(Taxon) %>% 
  summarise(totobs = sum(Count), # counts bc some observation records have mult individuals
            sizeclasses = n_distinct(Size_class), # number of size classes
            cameras = n_distinct(Camera) # number of cameras appeared in
            ) %>% arrange(desc(totobs)) # arrange by most prevalent species
```

Camera names are unique to site-camera, so the species with camera tally at 7 appear in all sites in all cameras. Only 7 species occur in all cameras.

## Species overlap between sites

```{r Site assemblages}

kaku <- data_ruv %>% filter(site_ID == 'hale_kaku') %>% select(Camera, Taxon)
kinalea <- data_ruv %>% filter(site_ID == 'hale_kinalea') %>% select(Camera, Taxon)

kaku %>% distinct(Taxon) %>% filter(Taxon %in% kinalea$Taxon)
# 27 species occur in both sites

# species exclusive to Hale Kaku: 10
kaku %>% distinct(Taxon) %>% filter(!Taxon %in% kinalea$Taxon)

# species exclusive to Hale Kinalea: 6
kinalea %>% distinct(Taxon) %>% filter(!Taxon %in% kaku$Taxon)

```

```{r Species cameras}
# number of cameras each species appeared in
# remember Hale Kaku had one camera failure, so its max = 3
kaku %>% group_by(Taxon) %>% 
  summarise(cameras = n_distinct(Camera)) %>% arrange(desc(cameras))
kinalea %>% group_by(Taxon) %>% 
  summarise(cameras = n_distinct(Camera)) %>% arrange(desc(cameras))

# number of species per camera
kaku %>% group_by(Camera) %>% summarise(totsp = n_distinct(Taxon))
kinalea %>% group_by(Camera) %>% summarise(totsp = n_distinct(Taxon))

```

Interesting camera-wise differences in Hale Kinalea. The deep camera at the start of the transect is an outlier compared to the other three.

## Species replicate numbers

```{r Species replicates, message = F, echo = F}

# Total observations per species per site
sp_reps <- data_ruv %>% group_by(site_ID, Taxon) %>% summarise(occurrences = sum(Count)) %>% ungroup

sp_reps %>% arrange(desc(occurrences)) %>% head(20) # view top 20

# plot the replicates per species for each site
# Hale Kaku first
reps.kaku <- ggplot(data = sp_reps %>% filter(site_ID == 'hale_kaku')) +
  geom_col(aes(x = reorder(Taxon, -occurrences), y = occurrences), fill = 'grey70') +
  theme_classic(base_size = 13) + 
  theme(axis.text.x = element_blank(), axis.title.x = element_blank(), axis.ticks.x = element_blank()) +
  scale_y_log10() + labs(title = "Hale Kaku", 
                         subtitle = paste0(sp_reps %>% filter(occurrences < 10, site_ID == 'hale_kaku') %>% nrow, ' species with < 10 occurrences'))
# Hale Kinalea
reps.kinalea <- ggplot(data = sp_reps %>% filter(site_ID == 'hale_kinalea')) +
  geom_col(aes(x = reorder(Taxon, -occurrences), y = occurrences), fill = 'grey70') +
  theme_classic(base_size = 13) + 
  theme(axis.text.x = element_blank(), axis.title.x = element_blank(), axis.ticks.x = element_blank()) +
  scale_y_log10() + labs(title = "Hale Kinalea", 
                         subtitle = paste0(sp_reps %>% filter(occurrences < 10, site_ID == 'hale_kinalea') %>% nrow, ' species with < 10 occurrences'))

reps.kaku + reps.kinalea

```

Still a pretty steep/skewed distribution with the log scale, so the number of occurrences/sample size per species without accounting for staying time is super heterogeneous. Dominated by damselfish, of course.

## Distribution checks: staying time (*T*<sub>ij</sub>)

The model uses maximum likelihood estimation to estimate expected staying times, which would follow either a gamma or exponential probability distribution. What do the raw data look like in terms of the distribution shape? This is the duration/staying time for every camera *i* and every detection *j*

```{r Staying time distributions, site, warning = F, message = F}

# convert this to a lubridate duration data type
data_ruv$entrytime_c <- ms(data_ruv$Time_entry) %>% as.duration
data_ruv$exittime_c <- ms(data_ruv$Time_exit) %>% as.duration
data_ruv$staytime <- with(data_ruv, exittime_c - entrytime_c) # just get staying time duration

ggplot(data = data_ruv) +
  geom_density(aes(x = staytime, group = site_ID, color = site_ID), alpha = 0.5) +
  theme_classic(base_size = 13) + labs(x = "Staying time (s)") +
  scale_color_cherulean(palette = 'gomphosus', discrete = T)

# just for ease of looking at the differences, but this is super consistent!
ggplot(data = data_ruv) +
  geom_density(aes(x = staytime, group = site_ID, fill = site_ID, color = site_ID), alpha = 0.3) +
  theme_classic(base_size = 13) + labs(x = "Staying time (s)") +
  scale_x_log10() +
  scale_fill_cherulean(palette = 'gomphosus', discrete = T) +
  scale_color_cherulean(palette = 'gomphosus', discrete = T)

```

Given the shape of these two distributions and it's center at 1, I'd pick a gamma distribution over an exponential distribution for the model estimating expected staying time. But, this is only aggregated at the site level. Let's see the distributions for the top 15 occurring species.

```{r Staying time distributions, species-site, warning = F, message = F, echo = F}
# top 15 occurring species
top_kaku <- sp_reps %>% arrange(desc(occurrences)) %>% 
  filter(site_ID == 'hale_kaku') %>% top_n(15) %>% pull(Taxon)
top_kinalea <- sp_reps %>% arrange(desc(occurrences)) %>% 
  filter(site_ID == 'hale_kinalea') %>% top_n(15) %>% pull(Taxon)

ggplot(data = data_ruv %>% filter(Taxon %in% top_kaku, site_ID == 'hale_kaku')) +
  geom_density(aes(x = staytime, group = Taxon, color = Taxon), size = 0.5) +
  theme_classic(base_size = 13) + labs(x = "Staying time (s)", title = "Hale Kaku", subtitle = "Staying time distributions for top 15 occurring species") +
  scale_color_cherulean(palette = 'gomphosus', discrete = T, alpha = 0.5) + guides(color = 'none')

ggplot(data = data_ruv %>% filter(Taxon %in% top_kaku, site_ID == 'hale_kinalea')) +
  geom_density(aes(x = staytime, group = Taxon, color = Taxon), size = 0.5) +
  theme_classic(base_size = 13) + labs(x = "Staying time (s)", title = "Hale Kinalea", subtitle = "Staying time distributions for top 15 occurring species") +
  scale_color_cherulean(palette = 'gomphosus', discrete = T, alpha = 0.5) + guides(color = 'none')

```

## Distribution checks: detections/occurrences (*Y<sub>i</sub>*)

Detections and occurrences follow a discrete distribution like Poisson or negative binomial because it's kind of like presence absence count data. Poisson would probably be good enough unless the data is overdispersed, but that's not something we can visually check without fitting models. Not like staying time, this is just number of detections per camera which we already tallied above.

Seems to fit a Poisson

```{r Detection per camera distribution, warning = F, message = F}

# assume a detection is per individual every time they enter the video screen
sp_decs <- data_ruv %>% group_by(Taxon, Camera, site_ID) %>% summarise(occurrences = sum(Count))
head(sp_decs, 10)

ggplot(data = sp_decs %>% filter(site_ID == 'hale_kaku')) +
  geom_density(aes(x = occurrences, group = Taxon, color = Taxon), size = 0.5) +
  theme_classic(base_size = 13) + labs(x = "Number of occurrences", title = "Hale Kaku", subtitle = "Number of occurrences distribution") +
  scale_color_cherulean(palette = 'gomphosus', discrete = T, alpha = 0.5) + guides(color = 'none')

ggplot(data = sp_decs %>% filter(site_ID == 'hale_kinalea')) +
  geom_density(aes(x = occurrences, group = Taxon, color = Taxon), size = 0.5) +
  theme_classic(base_size = 13) + labs(x = "Number of occurrences", title = "Hale Kinalea", subtitle = "Number of occurrences distribution") +
  scale_color_cherulean(palette = 'gomphosus', discrete = T, alpha = 0.5) + guides(color = 'none')

```

## Accumulation curves

Not sure why some cameras have such an odd saturation pattern when we split by cameras, but that may be an artefact of the camera placement adding to noise? Site-wise saturation holds up though!

```{r SAC, message = F, warning = F, eval = T}

## SAC data set up and prep

data_ruv <- data_ruv %>% arrange(site_ID, Camera, VidFile, entrytime_c)
#  timestamps are by video but we want them to be timestamps relative to total observation time, not video time.
cameras <- data_ruv %>% distinct(site_ID, Camera, VidFile)
ncam <- cameras %>% group_by(site_ID, Camera) %>% summarise(ncam = n_distinct(VidFile)) %>% pull(ncam)
seq <- ''
  for (i in 1:length(ncam)) {
    seq <- c(seq, 1:ncam[i])
  } # generate a sequence vector to identify the nominal order of video files
seq <- seq[-1] # trim that dummy start

cameras$VidSeq <- seq

data_ruv <- left_join(data_ruv, cameras, by=c('site_ID', 'Camera', 'VidFile'))
data_ruv$VidSeq <- as.numeric(data_ruv$VidSeq)

# make the timestamps relative to site and not video file
# all videos duration = 11:48 except for deep_0 = 17:42
for (i in 2:5) {
  # loop for each video file in order(1-4 or 5) add a multiple of the video file length
  # 2:5 because the first files don't need fixing
  # for the 11:48 videos
  data_ruv$SACentry[data_ruv$VidSeq == i & data_ruv$Camera != 'deep_0'] <- data_ruv$entrytime_c[data_ruv$VidSeq == i & data_ruv$Camera != 'deep_0'] + (i-1)*(dminutes(11) + dseconds(48))
  # for deep_0 17:42 videos
  data_ruv$SACentry[data_ruv$VidSeq == i & data_ruv$Camera == 'deep_0'] <- data_ruv$entrytime_c[data_ruv$VidSeq == i & data_ruv$Camera == 'deep_0'] + (i-1)*(dminutes(17) + dseconds(42))
}

# just put the time stamps in for first video files
data_ruv$SACentry[data_ruv$VidSeq == 1] <- data_ruv$entrytime_c[data_ruv$VidSeq == 1]
data_ruv$VidSeq <- NULL # get rid of these dummy objects
rm(cameras, ncam, seq)

## Calculate cumulative species richness over time
# make a dataframe to populate species accumulation per timestamp
SAC <- data_ruv %>% select(site_ID, Camera, SACentry) # matches the row index of data_ruv

# make the SAC times relative to the time of first observation
for (i in 1:7) {
  time1 <- SAC$SACentry[which(SAC$Camera == unique(SAC$Camera)[i])[1]]
  for (j in which(SAC$Camera == unique(SAC$Camera)[i])) {
    SAC$SACentry[j] <- SAC$SACentry[j] - time1 # take every time stamp and subtract time1 from it
  }
}
rm(time1)

# for every row at every site-camera, calculate the species number accumulation through time
for (i in 1:7) {
  for (j in which(SAC$Camera == unique(SAC$Camera)[i])) {
    if (j == which(SAC$Camera == unique(SAC$Camera)[i])[1]) { # the first row from each site represents the first species record, so these will always start at 1
      SAC$spN[j] <- 1
    }
    else {
      SAC$spN[j] <- data_ruv$Taxon[which(data_ruv$Camera == unique(data_ruv$Camera)[i])[1]:j] %>% n_distinct # number of unique species from the first row of the site to row j
    }
  }
}

## See raw SACs
ggplot() +
  theme_classic(base_size=13) +
  geom_point(data = SAC, aes(x = SACentry, y = spN, color = Camera), size=0.5, shape = 21, alpha=0.2) +
  labs(x='Observation (s)', y='Cumulative number of species observed', title = "SAC by cameras") +
  theme(axis.line = element_line(size=0.2)) +
  scale_color_cherulean(palette = "gomphosus", discrete = T) +
  coord_cartesian(ylim=c(0,35), xlim = c(0,2700))

# check by site
ggplot() +
  theme_classic(base_size=13) +
  geom_point(data = SAC, aes(x = SACentry, y = spN, color = site_ID), size=0.5, shape = 21, alpha=0.2) +
  labs(x='Observation (s)', y='Cumulative number of species observed', title = "SAC for sites") +
  theme(axis.line = element_line(size=0.2)) +
  scale_color_cherulean(palette = "gomphosus", discrete = T) +
  coord_cartesian(ylim=c(0,35), xlim = c(0,2700))

```

Try fitting proper nonlinear regression models for the saturation curves

``` {r SAC modelling for sites}

require(nlstools)
SAC_curve <- as.list(rep(0,2)) # info to fill with asymptotic non linear models
SAC_pred <- as.list(rep(0,2)) # object to fill with confidence interval info
set.seed(24)
for (i in 1:2) {
  # model fitting
  SAC_curve[[i]] <- nls(formula = spN ~ a - (a-b) * exp(-c* SACentry), 
                        data = SAC %>% filter(site_ID == unique(SAC$site_ID)[i]), 
                        start = list(a=20, b=0.7, c=0.001))
}

for (i in 1:2) {
  SAC_pred[[i]] <- nlsBootPredict(nlsBoot(SAC_curve[[i]], niter=500), 
                                  newdata = data.frame(SACentry = seq(0, 2700, length.out = sum((SAC$site_ID == unique(SAC$site_ID)[i])+0))), 
                                  interval = "confidence") %>% as.data.frame
  colnames(SAC_pred[[i]])[2:3] <- c('lwr', 'upr')
  SAC_pred[[i]]$SACentry <- seq(0, 2700, length.out = sum((SAC$site_ID == unique(SAC$site_ID)[i])+0))
}

plot_SACs <- ggplot() +
  theme_classic(base_size=13) +
  labs(x='Observation (s)', y='Cumulative number of species observed') +
  geom_point(data = SAC, aes(x = SACentry, y = spN, color = site_ID), size=0.5, shape = 21, alpha=0.2) +
  theme(axis.line = element_line(size=0.2)) +
  scale_color_cherulean(palette = "gomphosus", discrete = T) +
  coord_cartesian(ylim=c(0,35), xlim = c(0,2700))

palette = cherulean_palettes[['gomphosus']][c(2,7)]
for (i in 1:2) {
 plot_SACs <- plot_SACs +
    geom_ribbon(data = SAC_pred[[i]], aes(ymin=lwr, ymax=upr, x=SACentry), 
                fill=palette[i], alpha=0.2) +
    geom_line(data = SAC_pred[[i]], aes(x = SACentry, y = Median), color=palette[i], size=0.5)
}
  
plot_SACs


```



``` {r SAC modelling for site-cameras, error = T, warning = F, message = F}

require(nlstools)
SAC_curve <- as.list(rep(0,7)) # info to fill with asymptotic non linear models
SAC_pred <- as.list(rep(0,7)) # object to fill with confidence interval info
set.seed(24)
for (i in 1:7) {
  # model fitting
  SAC_curve[[i]] <- nls(formula = spN ~ a - (a-b) * exp(-c* SACentry), 
                        data = SAC %>% filter(Camera == unique(SAC$Camera)[i]), 
                        start = list(a=15, b=0.7, c=0.0005))
}

# only camera 7 didn't converge

for (i in 1:6) {
  SAC_pred[[i]] <- nlsBootPredict(nlsBoot(SAC_curve[[i]], niter=500), 
                                  newdata = data.frame(SACentry = seq(0, 2700, length.out = sum((SAC$Camera == unique(SAC$Camera)[i])+0))), 
                                  interval = "confidence") %>% as.data.frame
  colnames(SAC_pred[[i]])[2:3] <- c('lwr', 'upr')
  SAC_pred[[i]]$SACentry <- seq(0, 2700, length.out = sum((SAC$Camera == unique(SAC$Camera)[i])+0))
}

plot_SACs <- ggplot() +
  theme_classic(base_size=13) +
  labs(x='Observation time (s)', y='Cumulative species richness', title = "SACs by camera") +
  geom_point(data = SAC, aes(x = SACentry, y = spN, shape = site_ID), size=1, alpha=0.5, color = 'grey75') +
  theme(axis.line = element_line(size=0.2)) +
  coord_cartesian(ylim=c(0,35), xlim = c(0,2700))

for (i in 1:6) {
 plot_SACs <- plot_SACs +
    geom_ribbon(data = SAC_pred[[i]], aes(ymin=lwr, ymax=upr, x=SACentry), 
                fill=palette[i], alpha=0.2) +
    geom_line(data = SAC_pred[[i]], aes(x = SACentry, y = Median), linetype=ifelse(unique(SAC$Camera)[i] %in% unique(kaku$Camera), 'solid', 'longdash'), size=0.5, color = 'black')
}
  
plot_SACs


```

## Species abundance distributions

Let's look at the SADs for the two sites, get a sense for potential patterns between the detections and species abundances. SADs per site but also per camera

``` {r SADs}

# aggregate data so that each row is a species with the right nestedness
dt_SAD_site <- sp_decs %>% group_by(site_ID, Taxon) %>% summarise(occurrences = sum(occurrences))

dt_SAD_camera <- sp_decs %>% group_by(site_ID, Camera, Taxon) %>% summarise(occurrences = sum(occurrences))

ggplot(data = dt_SAD_site) +
  geom_density(aes(x = occurrences, color = site_ID)) +
  theme_classic(base_size = 13) + 
  labs(x = "Abundance classes", y = "Relative number of species",
       title = "SADs by site")

ggplot(data = dt_SAD_camera) +
  geom_density(aes(x = occurrences, color = Camera)) +
  theme_classic(base_size = 13) + 
  labs(x = "Abundance classes", y = "Relative number of species",
       title = "SADs by camera")

ggplot(data = dt_SAD_site) +
  geom_density(aes(x = occurrences, color = site_ID)) +
  theme_classic(base_size = 13) + scale_x_log10() +
  labs(x = "Abundance classes", y = "Relative number of species",
       title = "SADs by site", subtitle = "log-transformed")

ggplot(data = dt_SAD_camera) +
  geom_density(aes(x = occurrences, color = Camera)) +
  theme_classic(base_size = 13) + scale_x_log10() +
  labs(x = "Abundance classes", y = "Relative number of species",
       title = "SADs by camera", subtitle = "log-transformed")

```